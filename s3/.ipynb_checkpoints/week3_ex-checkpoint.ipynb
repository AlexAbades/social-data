{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pearson Correlation:**\n",
    "\n",
    "Is a measurement that indicates how strong two variables are correlated, specifically, the degree of linear association between two variables. It also indicates if they have positive or negative correlation (proportional or inversely proportional). It ranges from -1 to 1, where 1 indicates a perfect positive correlation and -1 a perfect negative correlation. \n",
    "\n",
    "The equation is: \n",
    "\n",
    "$ r = \\frac{N\\sum{XY}-(\\sum{X}\\sum{Y})}{\\sqrt{ [N\\sum{x^2}-(\\sum{x})^2 ][N\\sum{y^2}-(\\sum{y})^2 }]} $\n",
    "\n",
    "And Pearson Correlation might give a wrong lecture on the data correlation if this one has another type of correlation, i.e. Non-linear correlation.\n",
    "Or without going that far, on the other day example, where we had 4 different datasets with the same Pearson correlation. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bar vs Histograms Plots**\n",
    "\n",
    "Bar Charts are visual representations of *Categorical Data*. where each category is represented by a bar which the heigth is proportional to the values it represents. \n",
    "Histograms on the other hand are representations of *numerical data*, where the data is divided into intervals and the proportion of the data that fall into that interval are represented by the height.\n",
    "In the coffee example, we could see that at the first visualisation it had a categorial representation where each country was a category. and the amount of coffee was the height of the category. \n",
    "In the second visual representation, we could see that instead of countries, it had different pre defined categories, where each category represented an ammount of coffee consumption. then the eight of each category was the number of countries that fell inside this consumtion. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Right bin-size in the histogram**\n",
    "\n",
    "There are different methods to choose the right amount of bins for a histogram representaytion, some of them are: \n",
    "\n",
    "- Square-root choice: The square root of the number of observations in the data.\n",
    "\n",
    "- Sturges' formula: The logarithm of the number of observations in the data. Eq:  1 + log2(N).  N= num of observations. \n",
    "\n",
    "- Freedman-Diaconis rule: Interquartile range (IQR) of the data. The number of bins is calculated as 2 x IQR / (N)^(1/3), where IQR is the difference between the third quartile and the first quartile of the data, and N is the number of observations in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Jitter Plot**\n",
    "\n",
    "The jitter plot basicaaly shifts each point of the data set a random ammount so 2 points that have the same value, and thus, the point's won't lay in the same posistion and we could see how many points have a specific value. \n",
    "\n",
    "**Figure 2-3**\n",
    "\n",
    "The figure in 2-3 explains the importance of how where we place the first bin on the histogram and the width of them can change the visual representation that we can get of them.\n",
    "\n",
    "**When can KDE be misleading?**\n",
    "\n",
    "There are some handicaps when trying to plot data with KDE.\n",
    "\n",
    "- Sensitive to the choice of bandwidth: The bandwidth parameter controls the degree of smoothing in the density estimate. If the bandwidth is too small, the estimate can be too noisy, and if it is too large, the estimate can be oversmoothed and miss important features of the data. Selecting an appropriate bandwidth is crucial, and different methods exist to estimate it.\n",
    "\n",
    "- Difficulty in interpreting modes and tails: The modes or peaks in the density plot can be difficult to interpret, particularly if they are close together. Also, the tails of the density plot may not be accurate, particularly if there are few data points in those regions.\n",
    "\n",
    "- Not suitable for high-dimensional data: Kernel density estimation becomes computationally expensive in high-dimensional spaces, and requires a large amount of data to achieve reliable estimates. In such cases, other visualization techniques may be more appropriate.\n",
    "\n",
    "**Intuitivity of CDF**\n",
    "Cumulative density plots are less intuitive in the sense that you cannot get an exact picture of what's going on by just looking at the plot. While with bar plots and kernel distributions we can get an exact number of what are we aiming for. If we are interested in how probable is a specific event, a CDF won't clarify that. \n",
    "The point here is that each plot has a specific meaning, so depending on what we want to represent we can use one or another. \n",
    "\n",
    "**Quantile Plot and Probability plot** \n",
    "A quantile plot, also known as a probability plot, is the inverse of the cumulative distribution. It's basically used to check whether a probability distribution follows a specific distribution ot not. \n",
    "The most used case is to check if a specific distribution follows a gaussian distribution, as the inverse of the gaussian CDF it's a straight line, all the points that fall outside the straigth line will not follow a gaussian distribution. \n",
    "\n",
    "**Median, Mean and related summaries** \n",
    "When using the mean, median, or related measurements we can get a bad overview from the dataset as they could lead to misleading assumptions. \n",
    "Example; Categorical data with 3 values: 10, 20, 30.\n",
    "We have 20 points with values 1 and 3, 10 each. and 20 points on value 2. when calculating the mean, we'll obtain the value of 20, when caclculating the median, we'll also obtain the value of 20, we could think that we have a gaussian distribution while we are truly dealing with categorical data. \n",
    "\n",
    "**Box Plots** \n",
    "- Want to identify central tendencies. \n",
    "- Box Plots are useful when dealing with categorical data and we want to visualize the distributions of the different categories (also when we want to compare distributions from different datasets)\n",
    "- When we want identify potential outliers. \n",
    "- Displaying statistic summary like median, mean, quartiles... \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
